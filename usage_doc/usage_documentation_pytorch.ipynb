{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Learning Box Embeddings with Example\n",
    "\n",
    "This tutorial outlines the different functionalities available within the Box Embeddings package"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Installing the package on your machine\n",
    "\n",
    "*If you have the repo cloned*\n",
    "```\n",
    "pip install --editable . --user\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### A. Initialize a box tensor and check its parameters\n",
    "\n",
    "#### Standard Box Tensor\n",
    "To represent a Tensor as a Box, we use the class `BoxTensor`. The necessary parameter is `data` (a tensor)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "BoxTensor(tensor([[[ 1,  2],\n         [-1,  5]],\n\n        [[ 0,  2],\n         [-2,  3]],\n\n        [[-3,  3],\n         [-2,  4]]]))"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from box_embeddings.parameterizations.box_tensor import *\n",
    "# Let's create a toy example\n",
    "x_min = [-2.0]*50\n",
    "x_max = [0.0]*50\n",
    "data_x = torch.tensor([[[1,2],[-1,5]], [[0,2],[-2,3]], [[-3,3],[-2,4]]])\n",
    "#tensor = torch.tensor(np.random.rand(3, 2, 2))\n",
    "box_1 = BoxTensor(data_x)\n",
    "box_1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use several methods to look at the parameters of our box, such as"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2],\n",
      "        [ 0,  2],\n",
      "        [-3,  3]])\n",
      "tensor([[-1,  5],\n",
      "        [-2,  3],\n",
      "        [-2,  4]])\n",
      "tensor([[ 0.0000,  3.5000],\n",
      "        [-1.0000,  2.5000],\n",
      "        [-2.5000,  3.5000]])\n"
     ]
    }
   ],
   "source": [
    "# Lower left coordinate\n",
    "print(box_1.z)\n",
    "# Top right coordinate\n",
    "print(box_1.Z)\n",
    "# Center coordinate\n",
    "print(box_1.centre)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's broadcast our box to a new shape.. Broadcasting is often needed for different arithmetic operations. The function we\n",
    "will use is `broadcast()`, and the required parameter is `target_shape=()`, which specify the new shape\n",
    "for the box. This is very similar to `numpy.broadcast_to()`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previous shape is: (2, 3)\n",
      "after broadcasting: (2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor([[[1, 2, 3], [3, 4, 6]],\n",
    "          [[5, 6, 8], [7, 9, 5]]])\n",
    "box = BoxTensor(data)\n",
    "print('previous shape is:', box.box_shape)\n",
    "box.broadcast(target_shape=(2, 1, 3))\n",
    "print('after broadcasting:', box.box_shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Box Volume\n",
    "To calculate the volume of a box, we can use either the `soft_volume`, or the Bessel volume via `bessel_volume_approx`.\n",
    "To ensure numerical stability, we can use the log version via `log_soft_volume` or `log_bessel_volume_approx`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(75.4679)\n",
      "tensor(5.9605e+32)\n"
     ]
    }
   ],
   "source": [
    "from box_embeddings.modules.volume.soft_volume import soft_volume\n",
    "\n",
    "# Create data as tensors, and initialize a box\n",
    "data = torch.tensor([[-2.0]*100, [0.0]*100])\n",
    "box_1 = BoxTensor(data)\n",
    "\n",
    "# Logged Soft volume\n",
    "print(soft_volume(box_1))\n",
    "\n",
    "#Soft volume\n",
    "print(soft_volume(box_1, log_scale=False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Box Intersection\n",
    "\n",
    "To calculate the intersection of two boxes (which yields a box), we can use either `hard_intersection` or\n",
    "`gumbel_intersection`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxTensor(z=tensor([1.0000, 0.5000, 0.3333, 0.2500, 0.2000, 0.1667, 0.1429, 0.1250, 0.1111,\n",
      "        0.1000, 0.0909, 0.0833, 0.0769, 0.0714, 0.0667, 0.0625, 0.0588, 0.0556,\n",
      "        0.0526, 0.0500, 0.0476, 0.0455, 0.0435, 0.0417, 0.0400, 0.0385, 0.0370,\n",
      "        0.0357, 0.0345, 0.0333, 0.0323, 0.0312, 0.0303, 0.0294, 0.0286, 0.0278,\n",
      "        0.0270, 0.0263, 0.0256, 0.0250, 0.0244, 0.0238, 0.0233, 0.0227, 0.0222,\n",
      "        0.0217, 0.0213, 0.0208, 0.0204, 0.0200, 0.0196, 0.0192, 0.0189, 0.0185,\n",
      "        0.0182, 0.0179, 0.0175, 0.0172, 0.0169, 0.0167, 0.0164, 0.0161, 0.0159,\n",
      "        0.0156, 0.0154, 0.0152, 0.0149, 0.0147, 0.0145, 0.0143, 0.0141, 0.0139,\n",
      "        0.0137, 0.0135, 0.0133, 0.0132, 0.0130, 0.0128, 0.0127, 0.0125, 0.0123,\n",
      "        0.0122, 0.0120, 0.0119, 0.0118, 0.0116, 0.0115, 0.0114, 0.0112, 0.0111,\n",
      "        0.0110, 0.0109, 0.0108, 0.0106, 0.0105, 0.0104, 0.0103, 0.0102, 0.0101,\n",
      "        0.0100], grad_fn=<MaximumBackward>),\n",
      "Z=tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0.], grad_fn=<MinimumBackward>))\n",
      "BoxTensor(z=tensor([1.0486, 0.5789, 0.4259, 0.3502, 0.3051, 0.2751, 0.2538, 0.2378, 0.2254,\n",
      "        0.2155, 0.2074, 0.2007, 0.1950, 0.1901, 0.1859, 0.1822, 0.1789, 0.1760,\n",
      "        0.1734, 0.1711, 0.1690, 0.1671, 0.1653, 0.1637, 0.1622, 0.1609, 0.1596,\n",
      "        0.1585, 0.1574, 0.1563, 0.1554, 0.1545, 0.1537, 0.1529, 0.1521, 0.1514,\n",
      "        0.1508, 0.1501, 0.1495, 0.1490, 0.1484, 0.1479, 0.1474, 0.1470, 0.1465,\n",
      "        0.1461, 0.1457, 0.1453, 0.1449, 0.1446, 0.1442, 0.1439, 0.1436, 0.1433,\n",
      "        0.1430, 0.1427, 0.1424, 0.1421, 0.1419, 0.1416, 0.1414, 0.1411, 0.1409,\n",
      "        0.1407, 0.1405, 0.1403, 0.1401, 0.1399, 0.1397, 0.1395, 0.1393, 0.1392,\n",
      "        0.1390, 0.1388, 0.1387, 0.1385, 0.1384, 0.1382, 0.1381, 0.1379, 0.1378,\n",
      "        0.1377, 0.1375, 0.1374, 0.1373, 0.1372, 0.1371, 0.1369, 0.1368, 0.1367,\n",
      "        0.1366, 0.1365, 0.1364, 0.1363, 0.1362, 0.1361, 0.1360, 0.1359, 0.1358,\n",
      "        0.1357], grad_fn=<MulBackward0>),\n",
      "Z=tensor([-0.3160, -0.3160, -0.3160, -0.3160, -0.3161, -0.3161, -0.3161, -0.3162,\n",
      "        -0.3162, -0.3162, -0.3163, -0.3163, -0.3163, -0.3164, -0.3164, -0.3164,\n",
      "        -0.3165, -0.3165, -0.3166, -0.3166, -0.3166, -0.3167, -0.3167, -0.3168,\n",
      "        -0.3168, -0.3169, -0.3169, -0.3170, -0.3170, -0.3171, -0.3171, -0.3172,\n",
      "        -0.3172, -0.3173, -0.3174, -0.3174, -0.3175, -0.3176, -0.3176, -0.3177,\n",
      "        -0.3178, -0.3178, -0.3179, -0.3180, -0.3181, -0.3182, -0.3183, -0.3184,\n",
      "        -0.3185, -0.3186, -0.3187, -0.3188, -0.3189, -0.3190, -0.3192, -0.3193,\n",
      "        -0.3194, -0.3196, -0.3197, -0.3199, -0.3200, -0.3202, -0.3204, -0.3206,\n",
      "        -0.3208, -0.3210, -0.3213, -0.3215, -0.3218, -0.3220, -0.3223, -0.3227,\n",
      "        -0.3230, -0.3234, -0.3238, -0.3242, -0.3246, -0.3251, -0.3257, -0.3263,\n",
      "        -0.3270, -0.3277, -0.3285, -0.3294, -0.3305, -0.3316, -0.3330, -0.3345,\n",
      "        -0.3364, -0.3385, -0.3412, -0.3444, -0.3484, -0.3537, -0.3609, -0.3711,\n",
      "        -0.3869, -0.4144, -0.4741, -0.6931], grad_fn=<MulBackward0>))\n"
     ]
    }
   ],
   "source": [
    "from box_embeddings.modules.intersection import hard_intersection, gumbel_intersection\n",
    "\n",
    "# Create data as tensors, and initialize two boxes, box_1 and box_2\n",
    "x_min = [-2.0]*100\n",
    "x_max = [0.0]*100\n",
    "data_x = torch.tensor([x_min, x_max])\n",
    "box_1 = BoxTensor(data_x)\n",
    "\n",
    "y_min = [1/n for n in range(1, 101)]\n",
    "y_max = [1 - k for k in reversed(y_min)]\n",
    "data_y = torch.tensor([y_min, y_max], requires_grad=True)\n",
    "box_2 = BoxTensor(data_y)\n",
    "\n",
    "# Intersection of box_1 and box_2\n",
    "print(hard_intersection(box_1, box_2))\n",
    "\n",
    "# Gumbel intersection of box_1 and box_2\n",
    "print(gumbel_intersection(box_1, box_2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. Box Training\n",
    "In the following example, we train a simple box `box_2` to require it to be completely contained inside another box\n",
    "`box_1`. The training loop returns the best `box_2`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2924.1987\n",
      "Iteration 1, loss = 2894.2686\n",
      "Iteration 2, loss = 2730.0720\n",
      "Iteration 3, loss = 1665.2723\n",
      "Iteration 4, loss = 0.0000\n",
      "Iteration 5, loss = 0.0000\n",
      "Iteration 6, loss = 0.0000\n",
      "Iteration 7, loss = 0.0000\n",
      "Iteration 8, loss = 0.0000\n",
      "Iteration 9, loss = 0.0000\n",
      "Iteration 10, loss = 0.0000\n",
      "Iteration 11, loss = 0.0000\n",
      "Iteration 12, loss = 0.0000\n",
      "Iteration 13, loss = 0.0000\n",
      "Iteration 14, loss = 0.0000\n",
      "Iteration 15, loss = 0.0000\n",
      "Iteration 16, loss = 0.0000\n",
      "Iteration 17, loss = 0.0000\n",
      "Iteration 18, loss = 0.0000\n",
      "Iteration 19, loss = 0.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": "BoxTensor(tensor([[ 1.0000e+00,  1.9288e+00,  7.6992e-01,  2.9159e+00,  1.1253e+00,\n          8.8667e-01,  7.7884e-01,  7.1439e-01,  6.7064e-01,  6.3867e-01,\n          6.1416e-01,  5.9472e-01,  5.7889e-01,  5.6574e-01,  5.5464e-01,\n          5.4514e-01,  5.3692e-01,  5.2974e-01,  5.2341e-01,  4.8874e+01,\n          1.0975e+01,  6.6676e+00,  5.0054e+00,  4.1244e+00,  3.5791e+00,\n          3.2086e+00,  2.9408e+00,  2.7385e+00,  2.5807e+00,  2.4544e+00,\n          2.3513e+00,  2.2658e+00,  2.1939e+00,  2.1330e+00,  2.0809e+00,\n          2.0361e+00,  1.9973e+00,  1.9637e+00,  1.9345e+00,  1.9091e+00,\n          1.8871e+00,  1.8681e+00,  1.8518e+00,  1.8380e+00,  1.8263e+00,\n          1.8168e+00,  1.8093e+00,  1.8036e+00,  1.7997e+00,  1.7976e+00,\n          1.7972e+00,  1.7985e+00,  1.8016e+00,  1.8065e+00,  1.8133e+00,\n          1.8220e+00,  1.8328e+00,  1.8458e+00,  1.8613e+00,  1.8794e+00,\n          1.9005e+00,  1.9250e+00,  1.9533e+00,  1.9859e+00,  2.0237e+00,\n          2.0675e+00,  2.1185e+00,  2.1783e+00,  2.2490e+00,  2.3333e+00,\n          2.4351e+00,  2.5601e+00,  2.7165e+00,  2.9173e+00,  3.1834e+00,\n          3.5522e+00,  4.0957e+00,  4.9748e+00,  6.6348e+00,  1.0940e+01,\n          4.8835e+01,  4.8297e-01,  4.8623e-01,  4.9000e-01,  4.9440e-01,\n          4.9960e-01,  5.0581e-01,  5.1333e-01,  5.2262e-01,  5.3436e-01,\n          5.4966e-01,  5.7039e-01,  6.0014e-01,  6.4663e-01,  7.3053e-01,\n          9.3572e-01,  2.6762e+00,  4.4679e-01,  1.4389e+00,  1.0000e-02],\n        [ 9.9000e-01, -4.3894e-01,  5.5321e-01, -1.6762e+00,  6.4281e-02,\n          2.6947e-01,  3.5337e-01,  3.9986e-01,  4.2961e-01,  4.5034e-01,\n          4.6564e-01,  4.7738e-01,  4.8667e-01,  4.9419e-01,  5.0040e-01,\n          5.0560e-01,  5.1000e-01,  5.1377e-01,  5.1703e-01, -4.7836e+01,\n         -9.9399e+00, -5.6348e+00, -3.9748e+00, -3.0957e+00, -2.5522e+00,\n         -2.1834e+00, -1.9173e+00, -1.7165e+00, -1.5601e+00, -1.4351e+00,\n         -1.3333e+00, -1.2490e+00, -1.1783e+00, -1.1185e+00, -1.0675e+00,\n         -1.0237e+00, -9.8592e-01, -9.5326e-01, -9.2498e-01, -9.0052e-01,\n         -8.7941e-01, -8.6127e-01, -8.4580e-01, -8.3277e-01, -8.2198e-01,\n         -8.1327e-01, -8.0651e-01, -8.0162e-01, -7.9853e-01, -7.9718e-01,\n         -7.9757e-01, -7.9970e-01, -8.0358e-01, -8.0927e-01, -8.1683e-01,\n         -8.2635e-01, -8.3796e-01, -8.5182e-01, -8.6813e-01, -8.8713e-01,\n         -9.0913e-01, -9.3450e-01, -9.6370e-01, -9.9732e-01, -1.0361e+00,\n         -1.0809e+00, -1.1330e+00, -1.1939e+00, -1.2658e+00, -1.3513e+00,\n         -1.4544e+00, -1.5807e+00, -1.7385e+00, -1.9408e+00, -2.2086e+00,\n         -2.5791e+00, -3.1244e+00, -4.0054e+00, -5.6676e+00, -9.9750e+00,\n         -4.7873e+01,  4.7659e-01,  4.7026e-01,  4.6308e-01,  4.5486e-01,\n          4.4536e-01,  4.3426e-01,  4.2111e-01,  4.0528e-01,  3.8584e-01,\n          3.6133e-01,  3.2936e-01,  2.8561e-01,  2.2116e-01,  1.1333e-01,\n         -1.2530e-01, -1.9159e+00,  2.3008e-01, -9.2884e-01,  0.0000e+00]],\n       requires_grad=True))"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from box_embeddings.modules.volume.volume import Volume\n",
    "from box_embeddings.modules.intersection import Intersection\n",
    "\n",
    "# Initialize two boxes\n",
    "x_min = [-2.0 for n in range(1, 101)]\n",
    "x_max = [0.0 for k in reversed(x_min)]\n",
    "data_x = torch.tensor([x_min, x_max], requires_grad=True)\n",
    "box_1 = BoxTensor(data_x)\n",
    "\n",
    "y_min = [1/n for n in range(1, 101)]\n",
    "y_max = [1 - k for k in reversed(y_min)]\n",
    "data_y = torch.tensor([y_min, y_max], requires_grad=True)\n",
    "box_2 = BoxTensor(data_y)\n",
    "\n",
    "# Training loop\n",
    "learning_rate = 0.1\n",
    "\n",
    "def train(box_1, box_2, optimizer, epochs=1):\n",
    "    best_loss = int()\n",
    "    best_box_2 = None\n",
    "    box_vol = Volume()\n",
    "    box_int = Intersection()\n",
    "    for e in range(epochs):\n",
    "        loss = box_vol.forward(box_2) - box_vol.forward(box_int._forward(box_1, box_2))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if best_loss < loss.item():\n",
    "            best_loss = loss.item()\n",
    "            best_box_2 = box_2\n",
    "        print('Iteration %d, loss = %.4f' % (e, loss.item()))\n",
    "    return best_box_2\n",
    "\n",
    "optimizer =  torch.optim.SGD([data_y], lr=learning_rate)\n",
    "train(box_1, box_2, optimizer, epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
